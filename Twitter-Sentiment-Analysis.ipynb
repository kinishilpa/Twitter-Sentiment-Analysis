{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from tweepy) (2.21.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from requests>=2.11.1->tweepy) (2018.11.29)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\lenovo\\onedrive\\documents\\lib\\site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'wto7FjOxz5SIg4CSgS0LtmZV4'\n",
    "        consumer_secret = 'WL0TohXb2gflz6xgY3drKS8oPPgYAvi6arRiPJs5zfW85P0kam'\n",
    "        access_token = '996980107846848514-JjPI51foR461jvkXtjtlF6OSDVD5C2s'\n",
    "        access_token_secret = 'd8F8I58Jj7YQeo16KJGSQsjifE0ZdhNRPsFrewdk94H1v'\n",
    "  \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "  \n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "  \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "  \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Donald Trump', count = 200)\n",
    "    #print(tweets)\n",
    "  \n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} %\".format(100*(len(tweets) - len(ntweets) - len(ptweets))/len(tweets))) \n",
    "  \n",
    "    # printing first 5 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "    # printing first 5 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 40.54054054054054 %\n",
      "Negative tweets percentage: 21.62162162162162 %\n",
      "Neutral tweets percentage: 37.83783783783784 %\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "RT @dvillella: @realDonaldTrump Did you hear the latest con job?\n",
      "A certain presidential candidate said he would eliminate the deficit if he…\n",
      "@WordswithSteph @YoginiCrone Donald Trump has proven time and time again that he just can't do better than Barack O… https://t.co/xVkWbQR14e\n",
      "RT @People4Bernie: Over 50,000 people have attended @BernieSanders rallies since we won New Hampshire.\n",
      "\n",
      "Tacoma, WA - 17,000\n",
      "Richmond, CA -…\n",
      "RT @ewarren: This grassroots movement isn't just about defeating Donald Trump. Big, structural change means winning up and down the ticket.…\n",
      "RT @ThePubliusUSA: Perhaps I am a cynic, but it is very interesting that Maine, Tennessee and Alaska (Collins, Murkowski and Alexander) eac…\n",
      "RT @MsWerner: Sure, we have to get rid of Donald Trump, but just as important is the makeup of the House and the Senate. I've included a li…\n",
      "@BernieSanders Thanks to you Bernie we have Donald Trump.. And for that you cannot have my support.\n",
      "@washingtonpost Yay! To the military! Why would they investigate a soldier who is more of a patriot than Donald Tru… https://t.co/IGM3im9nHw\n",
      "RT @KTVU: Jerry Rice on the pardon of Eddie DeBartolo:  \"I take my hat off to Donald Trump for what he did... Today is a great day.\" https:…\n",
      "RT @BoycottUtah: It is Tuesday, February 18, 2020.  One citizen, I call for the removal from office by any legal means, the impeached fasci…\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "RT @davematt88: Donald Trump and other Republican officials are spreading this narrative that the economy was bad and he made it better. Th…\n",
      "RT @JYSexton: Hey. So it’s time for some hard truth. There are swathes of the American Left who are looking past Bloomberg’s racist, sexist…\n",
      "RT @JulianCastro: I’ll be LIVE from Las Vegas with MSNBC’s @mitchellreports in just a few minutes. \n",
      "\n",
      "Looking forward to talking about the u…\n",
      "RT @Strandjunker: It’s lucky for Donald Trump and Jared Kushner that they are just 2 spoiled white guys up to their eyeballs in criminal sh…\n",
      "RT @JoeBiden: We are in a battle for the soul of this nation. Donald Trump: \n",
      "\n",
      "- Fans the flames of hate and emboldens white supremacists\n",
      "-…\n",
      "If Harvey Weinstein doesn't go to jail tonight will put this under the same mistake of not getting Donald trump imp… https://t.co/gkwpzhsvSm\n",
      "RT @MaddowBlog: Any little money thing related to Donald Trump that has been fully reported, reveals a catastrophe. \n",
      "\n",
      "Watch: https://t.co/p…\n",
      "RT @Amy_Siskind: Trump is continuing his effort to rewrite history with himself as the victim.  An independent group of 1,000 judges called…\n",
      "@maddow It's gotta be scary for them...  Donald Trump is exposing the deep state swamp!!!\n",
      "RT @TomP__TomJWells: \"Across the ideological spectrum, ordinary Democrats like Bernie Sanders. That doesn’t mean he’ll beat Donald Trump. B…\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
